{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "pxIloV7r4H6i",
      "metadata": {
        "id": "pxIloV7r4H6i"
      },
      "source": [
        "# Pitch Synchronous Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "Gu0De8BMOapO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu0De8BMOapO",
        "outputId": "735db748-3adc-4c74-9bcc-428c5991c435"
      },
      "outputs": [],
      "source": [
        "MAIN_DIR = \".\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "174bd74e",
      "metadata": {
        "id": "174bd74e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "import scipy\n",
        "import scipy.signal\n",
        "import python_speech_features\n",
        "import pickle as pkl\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from functions import getVoiced, get_pitch_sync_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f427a281",
      "metadata": {
        "id": "f427a281"
      },
      "outputs": [],
      "source": [
        "def get_mfcc(audio, sr, use_librosa=False):\n",
        "    mfcc = []\n",
        "    frames = get_pitch_sync_frames(audio, sr)\n",
        "    for frame in frames:\n",
        "        if use_librosa:\n",
        "            mfcc_coeffs = librosa.feature.mfcc(\n",
        "                frame, sr=sr, n_mfcc=13, hop_length=len(frame) + 1, win_length=len(frame)\n",
        "            )\n",
        "        else:\n",
        "            mfcc_coeffs = python_speech_features.mfcc(\n",
        "                signal=frame, samplerate=sr, numcep=13, winlen=len(frame) / sr, winstep=len(frame) / sr, nfft=N_FFT\n",
        "            )\n",
        "        mfcc.append(mfcc_coeffs.flatten())\n",
        "    return np.array(mfcc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "67db04b7",
      "metadata": {
        "id": "67db04b7"
      },
      "outputs": [],
      "source": [
        "def extract_train_mfcc(use_librosa=False):\n",
        "    languages = [os.path.basename(x) for x in glob.glob(f\"{TRAIN_DIR}/*\")]\n",
        "    for language in languages:\n",
        "        print(\"Extracting Train MFCC features for\", language)\n",
        "        wav_files = sorted(glob.glob(f\"{TRAIN_DIR}/{language}/*.wav\"))\n",
        "        mfcc_features = []\n",
        "        for file in wav_files:\n",
        "            try:\n",
        "                audio, sr = librosa.load(file, sr=SR)\n",
        "                mfcc = get_mfcc(audio, sr, use_librosa)\n",
        "                mfcc_features.extend([mfcc[i] for i in range(mfcc.shape[0])])\n",
        "            except Exception as e:\n",
        "                print(file, e)\n",
        "                continue\n",
        "        filename = f\"{MFCC_TRAIN_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        np.save(filename, np.array(mfcc_features))\n",
        "        print(\"Saved MFCC features for\", language, \"in\", filename)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "84012c29",
      "metadata": {
        "id": "84012c29"
      },
      "outputs": [],
      "source": [
        "def extract_test_mfcc(use_librosa=False):\n",
        "    languages = [os.path.basename(x) for x in glob.glob(f\"{TEST_DIR}/*\")]\n",
        "    for language in languages:\n",
        "        print(\"Extracting Test MFCC features for\", language)\n",
        "        wav_files = sorted(glob.glob(f\"{TEST_DIR}/{language}/*.wav\"))\n",
        "        mfcc_features = []\n",
        "        for file in wav_files:\n",
        "            try:\n",
        "                audio, sr = librosa.load(file, sr=SR)\n",
        "                mfcc = get_mfcc(audio, sr)\n",
        "                mfcc_features.append(mfcc)\n",
        "            except Exception as e:\n",
        "                print(file, e)\n",
        "                continue\n",
        "        filename = f\"{MFCC_TEST_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        with open(filename, \"wb\") as file:\n",
        "            pkl.dump(mfcc_features, file)\n",
        "        print(\"Saved MFCC features for\", language, \"in\", filename)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "32ae20c4",
      "metadata": {
        "id": "32ae20c4"
      },
      "outputs": [],
      "source": [
        "def train(n_gaussians, use_librosa=False):\n",
        "    dirs = glob.glob(f\"{TRAIN_DIR}/*\")\n",
        "    languages = [os.path.basename(d) for d in dirs]\n",
        "    models = {}\n",
        "    for language in languages:\n",
        "        mfcc_filename = f\"{MFCC_TRAIN_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        mfcc_features = np.load(mfcc_filename)\n",
        "        print(f\"Training GMM for {language}\")\n",
        "        models[language] = GaussianMixture(n_gaussians, covariance_type=\"diag\", max_iter=MAX_ITER).fit(mfcc_features)\n",
        "    return models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "1accbcd5",
      "metadata": {
        "id": "1accbcd5"
      },
      "outputs": [],
      "source": [
        "def test(models, use_librosa=False):\n",
        "    dirs = glob.glob(f\"{TEST_DIR}/*\")\n",
        "    languages = sorted([os.path.basename(d) for d in dirs])\n",
        "    conf_matrix = {language: {lang: 0 for lang in languages} for language in languages}\n",
        "    for language in languages:\n",
        "        mfcc_filename = f\"{MFCC_TEST_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        with open(mfcc_filename, \"rb\") as file:\n",
        "            mfcc_features = pkl.load(file)\n",
        "        for mfcc in mfcc_features:\n",
        "            pred = \"\"\n",
        "            scores = {}\n",
        "            for lang in models:\n",
        "                scores[lang] = models[lang].score(mfcc)\n",
        "                if pred == \"\" or scores[pred] < scores[lang]:\n",
        "                    pred = lang\n",
        "            conf_matrix[language][pred] += 1\n",
        "    cf_matrix = np.zeros((len(languages), len(languages)))\n",
        "    language_mappings = {}\n",
        "    for i, language in enumerate(languages):\n",
        "        language_mappings[language] = i\n",
        "    for language in conf_matrix:\n",
        "        r = language_mappings[language]\n",
        "        for lang in conf_matrix[language]:\n",
        "            c = language_mappings[lang]\n",
        "            cf_matrix[r][c] = conf_matrix[language][lang]\n",
        "    return cf_matrix.trace() / cf_matrix.sum(), cf_matrix, language_mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a2a69a07",
      "metadata": {
        "id": "a2a69a07"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = f\"{MAIN_DIR}/dataset2/train\"\n",
        "TEST_DIR = f\"{MAIN_DIR}/dataset2/test\"\n",
        "MFCC_TRAIN_DIR = f\"{MAIN_DIR}/mfcc/train\"\n",
        "MFCC_TEST_DIR = f\"{MAIN_DIR}/mfcc/test\"\n",
        "MODELS_DIR = f\"{MAIN_DIR}/models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "794581fe",
      "metadata": {
        "id": "794581fe"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(MFCC_TRAIN_DIR):\n",
        "    os.makedirs(MFCC_TRAIN_DIR)\n",
        "if not os.path.isdir(MFCC_TEST_DIR):\n",
        "    os.makedirs(MFCC_TEST_DIR)\n",
        "if not os.path.isdir(MODELS_DIR):\n",
        "    os.makedirs(MODELS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f2f7a1c0",
      "metadata": {
        "id": "f2f7a1c0"
      },
      "outputs": [],
      "source": [
        "SR = 8000\n",
        "USE_LIBROSA = False\n",
        "USE_DELTAS = False\n",
        "N_FFT = 1024\n",
        "MAX_ITER = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "f261b961",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f261b961",
        "outputId": "1ad101a6-1492-490b-8f91-6c57aa8a2e93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting Train MFCC features for gujarathi\n",
            "Saved MFCC features for gujarathi in ./mfcc/train/gujarathi_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for manipuri\n",
            "Saved MFCC features for manipuri in ./mfcc/train/manipuri_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for telugu\n",
            "Saved MFCC features for telugu in ./mfcc/train/telugu_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for assamese\n",
            "Saved MFCC features for assamese in ./mfcc/train/assamese_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for odia\n",
            "Saved MFCC features for odia in ./mfcc/train/odia_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for marathi\n",
            "Saved MFCC features for marathi in ./mfcc/train/marathi_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for bengali\n",
            "./dataset2/train/bengali/f4_16.wav v cannot be empty\n",
            "Saved MFCC features for bengali in ./mfcc/train/bengali_psf_pitch_sync.npy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "extract_train_mfcc(USE_LIBROSA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "f3e86bc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3e86bc9",
        "outputId": "0c920387-2b00-4fb0-9c2d-f8c16848d2e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting Test MFCC features for gujarathi\n",
            "Saved MFCC features for gujarathi in ./mfcc/test/gujarathi_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for manipuri\n",
            "Saved MFCC features for manipuri in ./mfcc/test/manipuri_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for telugu\n",
            "Saved MFCC features for telugu in ./mfcc/test/telugu_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for assamese\n",
            "Saved MFCC features for assamese in ./mfcc/test/assamese_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for odia\n",
            "Saved MFCC features for odia in ./mfcc/test/odia_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for marathi\n",
            "Saved MFCC features for marathi in ./mfcc/test/marathi_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for bengali\n",
            "Saved MFCC features for bengali in ./mfcc/test/bengali_psf_pitch_sync.npy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "extract_test_mfcc(USE_LIBROSA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b605d242",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b605d242",
        "outputId": "931be0be-b244-4848-8a81-4f3bf44bb307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 8 gaussians: 0.9245283018867925\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 16 gaussians: 0.9056603773584906\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 32 gaussians: 0.9386792452830188\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 64 gaussians: 0.9669811320754716\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 128 gaussians: 0.9669811320754716\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 256 gaussians: 0.9622641509433962\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 512 gaussians: 0.9622641509433962\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 1024 gaussians: 0.9528301886792453\n",
            "\n"
          ]
        }
      ],
      "source": [
        "N = [8, 16, 32, 64, 128, 256, 512, 1024]\n",
        "best_models = {}\n",
        "best_accuracy = 0\n",
        "for n in N:\n",
        "    models = train(n, USE_LIBROSA)\n",
        "    print()\n",
        "    print(\"Testing the performance\")\n",
        "    acc, cf_matrix, language_mappings = test(models, USE_LIBROSA)\n",
        "    if acc > best_accuracy:\n",
        "        best_accuracy = acc\n",
        "        best_models = models.copy()\n",
        "    print(f\"Accuracy using {n} gaussians:\", acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "4f7d9d39",
      "metadata": {
        "id": "4f7d9d39"
      },
      "outputs": [],
      "source": [
        "# saving models\n",
        "for language in best_models:\n",
        "    filename = f\"{MODELS_DIR}/{language}_{'lib' if USE_LIBROSA else 'psf'}{'_pitch_sync'}.pkl\"\n",
        "    with open(filename, \"wb\") as file:\n",
        "        pkl.dump(best_models[language], file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "5fa58dad",
      "metadata": {
        "id": "5fa58dad"
      },
      "outputs": [],
      "source": [
        "acc, cf_matrix, language_mappings = test(best_models, USE_LIBROSA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "8e71eee3",
      "metadata": {
        "id": "8e71eee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9669811320754716\n",
            "{'assamese': 0, 'bengali': 1, 'gujarathi': 2, 'manipuri': 3, 'marathi': 4, 'odia': 5, 'telugu': 6}\n",
            "Confusion Matrix:\n",
            " [[30.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. 31.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. 29.  0.  0.  0.  2.]\n",
            " [ 0.  0.  0. 30.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. 30.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. 30.  0.]\n",
            " [ 0.  0.  3.  0.  1.  1. 25.]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\",  acc)\n",
        "print(language_mappings)\n",
        "print(\"Confusion Matrix:\\n\", cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "4d9c2c33",
      "metadata": {
        "id": "4d9c2c33"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assamese</th>\n",
              "      <th>bengali</th>\n",
              "      <th>gujarathi</th>\n",
              "      <th>manipuri</th>\n",
              "      <th>marathi</th>\n",
              "      <th>odia</th>\n",
              "      <th>telugu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>assamese</th>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bengali</th>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gujarathi</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>manipuri</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marathi</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>odia</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>telugu</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           assamese  bengali  gujarathi  manipuri  marathi  odia  telugu\n",
              "assamese         30        0          0         0        0     0       0\n",
              "bengali           0       31          0         0        0     0       0\n",
              "gujarathi         0        0         29         0        0     0       3\n",
              "manipuri          0        0          0        30        0     0       0\n",
              "marathi           0        0          0         0       30     0       1\n",
              "odia              0        0          0         0        0    30       1\n",
              "telugu            0        0          2         0        0     0      25"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = {}\n",
        "for i, language in enumerate(language_mappings):\n",
        "    df[language] = cf_matrix[i].astype(np.int32)\n",
        "df = pd.DataFrame(df, columns=language_mappings, index=language_mappings)\n",
        "df.to_csv(f\"{MAIN_DIR}/{'lib' if USE_LIBROSA else 'psf'}{'_pitch_sync'}.csv\", columns=language_mappings, index=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1386d9e1",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "0767bc91d6a71e2fcfaa3e34ef6383eab4c19e062312dc5ecfe1a27dfdba791e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
