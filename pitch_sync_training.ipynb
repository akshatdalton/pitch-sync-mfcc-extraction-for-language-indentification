{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pitch Synchronous Approach"
      ],
      "metadata": {
        "id": "pxIloV7r4H6i"
      },
      "id": "pxIloV7r4H6i"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "import sys\n",
        "MAIN_DIR = \"/content/gdrive/MyDrive/SSP\"\n",
        "sys.path.insert(0, MAIN_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu0De8BMOapO",
        "outputId": "735db748-3adc-4c74-9bcc-428c5991c435"
      },
      "id": "Gu0De8BMOapO",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python_speech_features"
      ],
      "metadata": {
        "id": "ZsoDueU9QHpL"
      },
      "id": "ZsoDueU9QHpL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "174bd74e",
      "metadata": {
        "id": "174bd74e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "import scipy\n",
        "import scipy.signal\n",
        "import python_speech_features\n",
        "import pickle as pkl\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from functions import getVoiced, get_pitch_sync_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f427a281",
      "metadata": {
        "id": "f427a281"
      },
      "outputs": [],
      "source": [
        "def get_mfcc(audio, sr, use_librosa=False):\n",
        "    mfcc = []\n",
        "    frames = get_pitch_sync_frames(audio, sr)\n",
        "    for frame in frames:\n",
        "        if use_librosa:\n",
        "            mfcc_coeffs = librosa.feature.mfcc(\n",
        "                frame, sr=sr, n_mfcc=13, hop_length=len(frame) + 1, win_length=len(frame)\n",
        "            )\n",
        "        else:\n",
        "            mfcc_coeffs = python_speech_features.mfcc(\n",
        "                signal=frame, samplerate=sr, numcep=13, winlen=len(frame) / sr, winstep=len(frame) / sr, nfft=N_FFT\n",
        "            )\n",
        "        mfcc.append(mfcc_coeffs.flatten())\n",
        "    return np.array(mfcc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "67db04b7",
      "metadata": {
        "id": "67db04b7"
      },
      "outputs": [],
      "source": [
        "def extract_train_mfcc(use_librosa=False):\n",
        "    languages = [os.path.basename(x) for x in glob.glob(f\"{TRAIN_DIR}/*\")]\n",
        "    for language in languages:\n",
        "        print(\"Extracting Train MFCC features for\", language)\n",
        "        wav_files = sorted(glob.glob(f\"{TRAIN_DIR}/{language}/*.wav\"))\n",
        "        mfcc_features = []\n",
        "        for file in wav_files:\n",
        "            try:\n",
        "                audio, sr = librosa.load(file, sr=SR)\n",
        "                mfcc = get_mfcc(audio, sr, use_librosa)\n",
        "                mfcc_features.extend([mfcc[i] for i in range(mfcc.shape[0])])\n",
        "            except Exception as e:\n",
        "                print(file, e)\n",
        "                continue\n",
        "        filename = f\"{MFCC_TRAIN_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        np.save(filename, np.array(mfcc_features))\n",
        "        print(\"Saved MFCC features for\", language, \"in\", filename)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "84012c29",
      "metadata": {
        "id": "84012c29"
      },
      "outputs": [],
      "source": [
        "def extract_test_mfcc(use_librosa=False):\n",
        "    languages = [os.path.basename(x) for x in glob.glob(f\"{TEST_DIR}/*\")]\n",
        "    for language in languages:\n",
        "        print(\"Extracting Test MFCC features for\", language)\n",
        "        wav_files = sorted(glob.glob(f\"{TEST_DIR}/{language}/*.wav\"))\n",
        "        mfcc_features = []\n",
        "        for file in wav_files:\n",
        "            try:\n",
        "                audio, sr = librosa.load(file, sr=SR)\n",
        "                mfcc = get_mfcc(audio, sr)\n",
        "                mfcc_features.append(mfcc)\n",
        "            except Exception as e:\n",
        "                print(file, e)\n",
        "                continue\n",
        "        filename = f\"{MFCC_TEST_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        with open(filename, \"wb\") as file:\n",
        "            pkl.dump(mfcc_features, file)\n",
        "        print(\"Saved MFCC features for\", language, \"in\", filename)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "32ae20c4",
      "metadata": {
        "id": "32ae20c4"
      },
      "outputs": [],
      "source": [
        "def train(n_gaussians, use_deltas=True, use_librosa=False):\n",
        "    dirs = glob.glob(f\"{TRAIN_DIR}/*\")\n",
        "    languages = [os.path.basename(d) for d in dirs]\n",
        "    models = {}\n",
        "    for language in languages:\n",
        "        mfcc_filename = f\"{MFCC_TRAIN_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        mfcc_features = np.load(mfcc_filename)\n",
        "        print(f\"Training GMM for {language}\")\n",
        "        models[language] = GaussianMixture(n_gaussians, covariance_type=\"diag\", max_iter=MAX_ITER).fit(mfcc_features)\n",
        "    return models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1accbcd5",
      "metadata": {
        "id": "1accbcd5"
      },
      "outputs": [],
      "source": [
        "def test(models, use_deltas=True, use_librosa=False):\n",
        "    dirs = glob.glob(f\"{TEST_DIR}/*\")\n",
        "    languages = sorted([os.path.basename(d) for d in dirs])\n",
        "    conf_matrix = {language: {lang: 0 for lang in languages} for language in languages}\n",
        "    for language in languages:\n",
        "        mfcc_filename = f\"{MFCC_TEST_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        with open(mfcc_filename, \"rb\") as file:\n",
        "            mfcc_features = pkl.load(file)\n",
        "        for mfcc in mfcc_features:\n",
        "            pred = \"\"\n",
        "            scores = {}\n",
        "            for lang in models:\n",
        "                scores[lang] = models[lang].score(mfcc)\n",
        "                if pred == \"\" or scores[pred] < scores[lang]:\n",
        "                    pred = lang\n",
        "            conf_matrix[language][pred] += 1\n",
        "    cf_matrix = np.zeros((len(languages), len(languages)))\n",
        "    language_mappings = {}\n",
        "    for i, language in enumerate(languages):\n",
        "        language_mappings[language] = i\n",
        "    for language in conf_matrix:\n",
        "        r = language_mappings[language]\n",
        "        for lang in conf_matrix[language]:\n",
        "            c = language_mappings[lang]\n",
        "            cf_matrix[r][c] = conf_matrix[language][lang]\n",
        "    return cf_matrix.trace() / cf_matrix.sum(), cf_matrix, language_mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "a2a69a07",
      "metadata": {
        "id": "a2a69a07"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = f\"{MAIN_DIR}/dataset/train\"\n",
        "TEST_DIR = f\"{MAIN_DIR}/dataset/test\"\n",
        "MFCC_TRAIN_DIR = f\"{MAIN_DIR}/mfcc/train\"\n",
        "MFCC_TEST_DIR = f\"{MAIN_DIR}/mfcc/test\"\n",
        "MODELS_DIR = f\"{MAIN_DIR}/models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "794581fe",
      "metadata": {
        "id": "794581fe"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(MFCC_TRAIN_DIR):\n",
        "    os.makedirs(MFCC_TRAIN_DIR)\n",
        "if not os.path.isdir(MFCC_TEST_DIR):\n",
        "    os.makedirs(MFCC_TEST_DIR)\n",
        "if not os.path.isdir(MODELS_DIR):\n",
        "    os.makedirs(MODELS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f2f7a1c0",
      "metadata": {
        "id": "f2f7a1c0"
      },
      "outputs": [],
      "source": [
        "SR = 8000\n",
        "USE_LIBROSA = False\n",
        "USE_DELTAS = False\n",
        "N_FFT = 1024\n",
        "MAX_ITER = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f261b961",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f261b961",
        "outputId": "1ad101a6-1492-490b-8f91-6c57aa8a2e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Train MFCC features for manipuri\n",
            "Saved MFCC features for manipuri in /content/gdrive/MyDrive/SSP/mfcc/train/manipuri_lib.npy\n",
            "\n",
            "Extracting Train MFCC features for assamese\n",
            "Saved MFCC features for assamese in /content/gdrive/MyDrive/SSP/mfcc/train/assamese_lib.npy\n",
            "\n",
            "Extracting Train MFCC features for gujarathi\n",
            "Saved MFCC features for gujarathi in /content/gdrive/MyDrive/SSP/mfcc/train/gujarathi_lib.npy\n",
            "\n",
            "Extracting Train MFCC features for telugu\n",
            "Saved MFCC features for telugu in /content/gdrive/MyDrive/SSP/mfcc/train/telugu_lib.npy\n",
            "\n",
            "Extracting Train MFCC features for odia\n",
            "Saved MFCC features for odia in /content/gdrive/MyDrive/SSP/mfcc/train/odia_lib.npy\n",
            "\n",
            "Extracting Train MFCC features for marathi\n",
            "Saved MFCC features for marathi in /content/gdrive/MyDrive/SSP/mfcc/train/marathi_lib.npy\n",
            "\n",
            "Extracting Train MFCC features for bengali\n",
            "Saved MFCC features for bengali in /content/gdrive/MyDrive/SSP/mfcc/train/bengali_lib.npy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "extract_train_mfcc(USE_LIBROSA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e86bc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3e86bc9",
        "outputId": "0c920387-2b00-4fb0-9c2d-f8c16848d2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Test MFCC features for assamese\n",
            "Saved MFCC features for assamese in /content/gdrive/MyDrive/SSP/mfcc/test/assamese_lib.npy\n",
            "\n",
            "Extracting Test MFCC features for gujarathi\n",
            "Saved MFCC features for gujarathi in /content/gdrive/MyDrive/SSP/mfcc/test/gujarathi_lib.npy\n",
            "\n",
            "Extracting Test MFCC features for manipuri\n",
            "Saved MFCC features for manipuri in /content/gdrive/MyDrive/SSP/mfcc/test/manipuri_lib.npy\n",
            "\n",
            "Extracting Test MFCC features for marathi\n",
            "Saved MFCC features for marathi in /content/gdrive/MyDrive/SSP/mfcc/test/marathi_lib.npy\n",
            "\n",
            "Extracting Test MFCC features for telugu\n",
            "Saved MFCC features for telugu in /content/gdrive/MyDrive/SSP/mfcc/test/telugu_lib.npy\n",
            "\n",
            "Extracting Test MFCC features for odia\n",
            "Saved MFCC features for odia in /content/gdrive/MyDrive/SSP/mfcc/test/odia_lib.npy\n",
            "\n",
            "Extracting Test MFCC features for bengali\n",
            "Saved MFCC features for bengali in /content/gdrive/MyDrive/SSP/mfcc/test/bengali_lib.npy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "extract_test_mfcc(USE_LIBROSA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b605d242",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b605d242",
        "outputId": "931be0be-b244-4848-8a81-4f3bf44bb307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMM for manipuri\n",
            "Training GMM for assamese\n",
            "Training GMM for gujarathi\n",
            "Training GMM for telugu\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 8 gaussians: 0.176056338028169\n",
            "\n",
            "Training GMM for manipuri\n",
            "Training GMM for assamese\n",
            "Training GMM for gujarathi\n",
            "Training GMM for telugu\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 16 gaussians: 0.14788732394366197\n",
            "\n",
            "Training GMM for manipuri\n",
            "Training GMM for assamese\n",
            "Training GMM for gujarathi\n",
            "Training GMM for telugu\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 32 gaussians: 0.19014084507042253\n",
            "\n",
            "Training GMM for manipuri\n",
            "Training GMM for assamese\n",
            "Training GMM for gujarathi\n",
            "Training GMM for telugu\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 64 gaussians: 0.14788732394366197\n",
            "\n",
            "Training GMM for manipuri\n",
            "Training GMM for assamese\n",
            "Training GMM for gujarathi\n",
            "Training GMM for telugu\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 128 gaussians: 0.14084507042253522\n",
            "\n",
            "Training GMM for manipuri\n",
            "Training GMM for assamese\n",
            "Training GMM for gujarathi\n",
            "Training GMM for telugu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1475302a63b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSE_DELTAS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSE_LIBROSA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOICED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing the performance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-a6e47d304048>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_gaussians, use_deltas, use_librosa, voiced)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmfcc_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training GMM for {language}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_gaussians\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"diag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_ITER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mmixture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0mlog_prob_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_resp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0mlower_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_lower_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_resp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_gaussian_mixture.py\u001b[0m in \u001b[0;36m_m_step\u001b[0;34m(self, X, log_resp)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         self.precisions_cholesky_ = _compute_precision_cholesky(\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariances_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         )\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_gaussian_mixture.py\u001b[0m in \u001b[0;36m_compute_precision_cholesky\u001b[0;34m(covariances, covariance_type)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimate_precision_error_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mprecisions_chol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprecisions_chol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, or increase reg_covar."
          ]
        }
      ],
      "source": [
        "N = [8, 16, 32, 64, 128, 256]\n",
        "best_models = {}\n",
        "best_accuracy = 0\n",
        "for n in N:\n",
        "    models = train(n, USE_DELTAS, USE_LIBROSA)\n",
        "    print()\n",
        "    print(\"Testing the performance\")\n",
        "    acc, cf_matrix, language_mappings = test(models, USE_DELTAS, USE_LIBROSA)\n",
        "    if acc > best_accuracy:\n",
        "        best_accuracy = acc\n",
        "        best_models = models.copy()\n",
        "    print(f\"Accuracy using {n} gaussians:\", acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f7d9d39",
      "metadata": {
        "id": "4f7d9d39"
      },
      "outputs": [],
      "source": [
        "# saving models\n",
        "for language in best_models:\n",
        "    filename = f\"{MODELS_DIR}/{language}_{'lib' if USE_LIBROSA else 'psf'}{'_pitch_sync'}.pkl\"\n",
        "    with open(filename, \"wb\") as file:\n",
        "        pkl.dump(best_models[language], file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fa58dad",
      "metadata": {
        "id": "5fa58dad"
      },
      "outputs": [],
      "source": [
        "acc, cf_matrix, language_mappings = test(best_models, USE_DELTAS, USE_LIBROSA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e71eee3",
      "metadata": {
        "id": "8e71eee3"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy:\",  acc)\n",
        "print(language_mappings)\n",
        "print(\"Confusion Matrix:\\n\", cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d9c2c33",
      "metadata": {
        "id": "4d9c2c33"
      },
      "outputs": [],
      "source": [
        "df = {}\n",
        "for i, language in enumerate(language_mappings):\n",
        "    df[language] = cf_matrix[i].astype(np.int32)\n",
        "df = pd.DataFrame(df, columns=language_mappings, index=language_mappings)\n",
        "df.to_csv(f\"{MAIN_DIR}/{'lib' if USE_LIBROSA else 'psf'}{'_pitch_sync'}.csv\", columns=language_mappings, index=True)\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}