{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "pxIloV7r4H6i",
      "metadata": {
        "id": "pxIloV7r4H6i"
      },
      "source": [
        "# Pitch Synchronous Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "Gu0De8BMOapO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu0De8BMOapO",
        "outputId": "735db748-3adc-4c74-9bcc-428c5991c435"
      },
      "outputs": [],
      "source": [
        "MAIN_DIR = \".\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "174bd74e",
      "metadata": {
        "id": "174bd74e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "import scipy\n",
        "import scipy.signal\n",
        "import python_speech_features\n",
        "import pickle as pkl\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from functions import getVoiced, get_pitch_sync_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f427a281",
      "metadata": {
        "id": "f427a281"
      },
      "outputs": [],
      "source": [
        "def get_mfcc(audio, sr, use_librosa=False):\n",
        "    mfcc = []\n",
        "    frames = get_pitch_sync_frames(audio, sr)\n",
        "    for frame in frames:\n",
        "        if use_librosa:\n",
        "            mfcc_coeffs = librosa.feature.mfcc(\n",
        "                frame, sr=sr, n_mfcc=13, hop_length=len(frame) + 1, win_length=len(frame)\n",
        "            )\n",
        "        else:\n",
        "            mfcc_coeffs = python_speech_features.mfcc(\n",
        "                signal=frame, samplerate=sr, numcep=13, winlen=len(frame) / sr, winstep=len(frame) / sr, nfft=N_FFT\n",
        "            )\n",
        "        mfcc.append(mfcc_coeffs.flatten())\n",
        "    return np.array(mfcc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "67db04b7",
      "metadata": {
        "id": "67db04b7"
      },
      "outputs": [],
      "source": [
        "def extract_train_mfcc(use_librosa=False):\n",
        "    languages = [os.path.basename(x) for x in glob.glob(f\"{TRAIN_DIR}/*\")]\n",
        "    for language in languages:\n",
        "        print(\"Extracting Train MFCC features for\", language)\n",
        "        wav_files = sorted(glob.glob(f\"{TRAIN_DIR}/{language}/*.wav\"))\n",
        "        mfcc_features = []\n",
        "        for file in wav_files:\n",
        "            try:\n",
        "                audio, sr = librosa.load(file, sr=SR)\n",
        "                mfcc = get_mfcc(audio, sr, use_librosa)\n",
        "                mfcc_features.extend([mfcc[i] for i in range(mfcc.shape[0])])\n",
        "            except Exception as e:\n",
        "                print(file, e)\n",
        "                continue\n",
        "        filename = f\"{MFCC_TRAIN_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        np.save(filename, np.array(mfcc_features))\n",
        "        print(\"Saved MFCC features for\", language, \"in\", filename)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "84012c29",
      "metadata": {
        "id": "84012c29"
      },
      "outputs": [],
      "source": [
        "def extract_test_mfcc(use_librosa=False):\n",
        "    languages = [os.path.basename(x) for x in glob.glob(f\"{TEST_DIR}/*\")]\n",
        "    for language in languages:\n",
        "        print(\"Extracting Test MFCC features for\", language)\n",
        "        wav_files = sorted(glob.glob(f\"{TEST_DIR}/{language}/*.wav\"))\n",
        "        mfcc_features = []\n",
        "        for file in wav_files:\n",
        "            try:\n",
        "                audio, sr = librosa.load(file, sr=SR)\n",
        "                mfcc = get_mfcc(audio, sr)\n",
        "                mfcc_features.append(mfcc)\n",
        "            except Exception as e:\n",
        "                print(file, e)\n",
        "                continue\n",
        "        filename = f\"{MFCC_TEST_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        with open(filename, \"wb\") as file:\n",
        "            pkl.dump(mfcc_features, file)\n",
        "        print(\"Saved MFCC features for\", language, \"in\", filename)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "32ae20c4",
      "metadata": {
        "id": "32ae20c4"
      },
      "outputs": [],
      "source": [
        "def train(n_gaussians, use_deltas=True, use_librosa=False):\n",
        "    dirs = glob.glob(f\"{TRAIN_DIR}/*\")\n",
        "    languages = [os.path.basename(d) for d in dirs]\n",
        "    models = {}\n",
        "    for language in languages:\n",
        "        mfcc_filename = f\"{MFCC_TRAIN_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        mfcc_features = np.load(mfcc_filename)\n",
        "        print(f\"Training GMM for {language}\")\n",
        "        models[language] = GaussianMixture(n_gaussians, covariance_type=\"diag\", max_iter=MAX_ITER).fit(mfcc_features)\n",
        "    return models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1accbcd5",
      "metadata": {
        "id": "1accbcd5"
      },
      "outputs": [],
      "source": [
        "def test(models, use_deltas=True, use_librosa=False):\n",
        "    dirs = glob.glob(f\"{TEST_DIR}/*\")\n",
        "    languages = sorted([os.path.basename(d) for d in dirs])\n",
        "    conf_matrix = {language: {lang: 0 for lang in languages} for language in languages}\n",
        "    for language in languages:\n",
        "        mfcc_filename = f\"{MFCC_TEST_DIR}/{language}_{'lib' if use_librosa else 'psf'}{'_pitch_sync'}.npy\"\n",
        "        with open(mfcc_filename, \"rb\") as file:\n",
        "            mfcc_features = pkl.load(file)\n",
        "        for mfcc in mfcc_features:\n",
        "            pred = \"\"\n",
        "            scores = {}\n",
        "            for lang in models:\n",
        "                scores[lang] = models[lang].score(mfcc)\n",
        "                if pred == \"\" or scores[pred] < scores[lang]:\n",
        "                    pred = lang\n",
        "            conf_matrix[language][pred] += 1\n",
        "    cf_matrix = np.zeros((len(languages), len(languages)))\n",
        "    language_mappings = {}\n",
        "    for i, language in enumerate(languages):\n",
        "        language_mappings[language] = i\n",
        "    for language in conf_matrix:\n",
        "        r = language_mappings[language]\n",
        "        for lang in conf_matrix[language]:\n",
        "            c = language_mappings[lang]\n",
        "            cf_matrix[r][c] = conf_matrix[language][lang]\n",
        "    return cf_matrix.trace() / cf_matrix.sum(), cf_matrix, language_mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a2a69a07",
      "metadata": {
        "id": "a2a69a07"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = f\"{MAIN_DIR}/dataset/train\"\n",
        "TEST_DIR = f\"{MAIN_DIR}/dataset/test\"\n",
        "MFCC_TRAIN_DIR = f\"{MAIN_DIR}/mfcc/train\"\n",
        "MFCC_TEST_DIR = f\"{MAIN_DIR}/mfcc/test\"\n",
        "MODELS_DIR = f\"{MAIN_DIR}/models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "794581fe",
      "metadata": {
        "id": "794581fe"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(MFCC_TRAIN_DIR):\n",
        "    os.makedirs(MFCC_TRAIN_DIR)\n",
        "if not os.path.isdir(MFCC_TEST_DIR):\n",
        "    os.makedirs(MFCC_TEST_DIR)\n",
        "if not os.path.isdir(MODELS_DIR):\n",
        "    os.makedirs(MODELS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f2f7a1c0",
      "metadata": {
        "id": "f2f7a1c0"
      },
      "outputs": [],
      "source": [
        "SR = 8000\n",
        "USE_LIBROSA = False\n",
        "USE_DELTAS = False\n",
        "N_FFT = 1024\n",
        "MAX_ITER = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f261b961",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f261b961",
        "outputId": "1ad101a6-1492-490b-8f91-6c57aa8a2e93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting Train MFCC features for gujarathi\n",
            "Saved MFCC features for gujarathi in .//mfcc/train/gujarathi_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for manipuri\n",
            "Saved MFCC features for manipuri in .//mfcc/train/manipuri_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for telugu\n",
            "Saved MFCC features for telugu in .//mfcc/train/telugu_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for assamese\n",
            "Saved MFCC features for assamese in .//mfcc/train/assamese_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for odia\n",
            "Saved MFCC features for odia in .//mfcc/train/odia_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for marathi\n",
            "Saved MFCC features for marathi in .//mfcc/train/marathi_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Train MFCC features for bengali\n",
            ".//dataset/train/bengali/f4_16.wav v cannot be empty\n",
            "Saved MFCC features for bengali in .//mfcc/train/bengali_psf_pitch_sync.npy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "extract_train_mfcc(USE_LIBROSA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f3e86bc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3e86bc9",
        "outputId": "0c920387-2b00-4fb0-9c2d-f8c16848d2e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting Test MFCC features for gujarathi\n",
            "Saved MFCC features for gujarathi in .//mfcc/test/gujarathi_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for manipuri\n",
            "Saved MFCC features for manipuri in .//mfcc/test/manipuri_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for telugu\n",
            "Saved MFCC features for telugu in .//mfcc/test/telugu_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for assamese\n",
            "Saved MFCC features for assamese in .//mfcc/test/assamese_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for odia\n",
            "Saved MFCC features for odia in .//mfcc/test/odia_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for marathi\n",
            "Saved MFCC features for marathi in .//mfcc/test/marathi_psf_pitch_sync.npy\n",
            "\n",
            "Extracting Test MFCC features for bengali\n",
            "Saved MFCC features for bengali in .//mfcc/test/bengali_psf_pitch_sync.npy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "extract_test_mfcc(USE_LIBROSA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b605d242",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b605d242",
        "outputId": "931be0be-b244-4848-8a81-4f3bf44bb307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 8 gaussians: 0.9295774647887324\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 16 gaussians: 0.9295774647887324\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 32 gaussians: 0.9577464788732394\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 64 gaussians: 0.971830985915493\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 128 gaussians: 0.9788732394366197\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 256 gaussians: 0.9788732394366197\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n",
            "\n",
            "Testing the performance\n",
            "Accuracy using 1024 gaussians: 0.9859154929577465\n",
            "\n",
            "Training GMM for gujarathi\n",
            "Training GMM for manipuri\n",
            "Training GMM for telugu\n",
            "Training GMM for assamese\n",
            "Training GMM for odia\n",
            "Training GMM for marathi\n",
            "Training GMM for bengali\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m best_accuracy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m N:\n\u001b[0;32m----> 5\u001b[0m     models \u001b[39m=\u001b[39m train(n, USE_DELTAS, USE_LIBROSA)\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m()\n\u001b[1;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTesting the performance\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn [7], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(n_gaussians, use_deltas, use_librosa)\u001b[0m\n\u001b[1;32m      7\u001b[0m     mfcc_features \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(mfcc_filename)\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining GMM for \u001b[39m\u001b[39m{\u001b[39;00mlanguage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     models[language] \u001b[39m=\u001b[39m GaussianMixture(n_gaussians, covariance_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdiag\u001b[39;49m\u001b[39m\"\u001b[39;49m, max_iter\u001b[39m=\u001b[39;49mMAX_ITER)\u001b[39m.\u001b[39;49mfit(mfcc_features)\n\u001b[1;32m     10\u001b[0m \u001b[39mreturn\u001b[39;00m models\n",
            "File \u001b[0;32m~/Sem7/SSP/pitch-sync-mfcc-extraction-for-language-indentification/venv/lib/python3.8/site-packages/sklearn/mixture/_base.py:200\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m     \u001b[39m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \n\u001b[1;32m    177\u001b[0m \u001b[39m    The method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m        The fitted mixture.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_predict(X, y)\n\u001b[1;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m~/Sem7/SSP/pitch-sync-mfcc-extraction-for-language-indentification/venv/lib/python3.8/site-packages/sklearn/mixture/_base.py:264\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mfor\u001b[39;00m n_iter \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    262\u001b[0m     prev_lower_bound \u001b[39m=\u001b[39m lower_bound\n\u001b[0;32m--> 264\u001b[0m     log_prob_norm, log_resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_e_step(X)\n\u001b[1;32m    265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_m_step(X, log_resp)\n\u001b[1;32m    266\u001b[0m     lower_bound \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_lower_bound(log_resp, log_prob_norm)\n",
            "File \u001b[0;32m~/Sem7/SSP/pitch-sync-mfcc-extraction-for-language-indentification/venv/lib/python3.8/site-packages/sklearn/mixture/_base.py:321\u001b[0m, in \u001b[0;36mBaseMixture._e_step\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_e_step\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    306\u001b[0m     \u001b[39m\"\"\"E step.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \n\u001b[1;32m    308\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39m        the point of each sample in X.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m     log_prob_norm, log_resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_estimate_log_prob_resp(X)\n\u001b[1;32m    322\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(log_prob_norm), log_resp\n",
            "File \u001b[0;32m~/Sem7/SSP/pitch-sync-mfcc-extraction-for-language-indentification/venv/lib/python3.8/site-packages/sklearn/mixture/_base.py:541\u001b[0m, in \u001b[0;36mBaseMixture._estimate_log_prob_resp\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_estimate_log_prob_resp\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    523\u001b[0m     \u001b[39m\"\"\"Estimate log probabilities and responsibilities for each sample.\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \n\u001b[1;32m    525\u001b[0m \u001b[39m    Compute the log probabilities, weighted log probabilities per\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m        logarithm of the responsibilities\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m     weighted_log_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_estimate_weighted_log_prob(X)\n\u001b[1;32m    542\u001b[0m     log_prob_norm \u001b[39m=\u001b[39m logsumexp(weighted_log_prob, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    543\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(under\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    544\u001b[0m         \u001b[39m# ignore underflow\u001b[39;00m\n",
            "File \u001b[0;32m~/Sem7/SSP/pitch-sync-mfcc-extraction-for-language-indentification/venv/lib/python3.8/site-packages/sklearn/mixture/_base.py:494\u001b[0m, in \u001b[0;36mBaseMixture._estimate_weighted_log_prob\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_estimate_weighted_log_prob\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    484\u001b[0m     \u001b[39m\"\"\"Estimate the weighted log-probabilities, log P(X | Z) + log weights.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[39m    weighted_log_prob : array, shape (n_samples, n_component)\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_estimate_log_prob(X) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_estimate_log_weights()\n",
            "File \u001b[0;32m~/Sem7/SSP/pitch-sync-mfcc-extraction-for-language-indentification/venv/lib/python3.8/site-packages/sklearn/mixture/_gaussian_mixture.py:760\u001b[0m, in \u001b[0;36mGaussianMixture._estimate_log_prob\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_estimate_log_prob\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m--> 760\u001b[0m     \u001b[39mreturn\u001b[39;00m _estimate_log_gaussian_prob(\n\u001b[1;32m    761\u001b[0m         X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmeans_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecisions_cholesky_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcovariance_type\n\u001b[1;32m    762\u001b[0m     )\n",
            "File \u001b[0;32m~/Sem7/SSP/pitch-sync-mfcc-extraction-for-language-indentification/venv/lib/python3.8/site-packages/sklearn/mixture/_gaussian_mixture.py:440\u001b[0m, in \u001b[0;36m_estimate_log_gaussian_prob\u001b[0;34m(X, means, precisions_chol, covariance_type)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m covariance_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdiag\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    437\u001b[0m     precisions \u001b[39m=\u001b[39m precisions_chol\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m    438\u001b[0m     log_prob \u001b[39m=\u001b[39m (\n\u001b[1;32m    439\u001b[0m         np\u001b[39m.\u001b[39msum((means\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m precisions), \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 440\u001b[0m         \u001b[39m-\u001b[39m \u001b[39m2.0\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49mdot(X, (means \u001b[39m*\u001b[39;49m precisions)\u001b[39m.\u001b[39;49mT)\n\u001b[1;32m    441\u001b[0m         \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mdot(X\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, precisions\u001b[39m.\u001b[39mT)\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[39melif\u001b[39;00m covariance_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mspherical\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    445\u001b[0m     precisions \u001b[39m=\u001b[39m precisions_chol\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
            "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "N = [8, 16, 32, 64, 128, 256, 1024, 2048, 4096]\n",
        "best_models = {}\n",
        "best_accuracy = 0\n",
        "for n in N:\n",
        "    models = train(n, USE_DELTAS, USE_LIBROSA)\n",
        "    print()\n",
        "    print(\"Testing the performance\")\n",
        "    acc, cf_matrix, language_mappings = test(models, USE_DELTAS, USE_LIBROSA)\n",
        "    if acc > best_accuracy:\n",
        "        best_accuracy = acc\n",
        "        best_models = models.copy()\n",
        "    print(f\"Accuracy using {n} gaussians:\", acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f7d9d39",
      "metadata": {
        "id": "4f7d9d39"
      },
      "outputs": [],
      "source": [
        "# saving models\n",
        "for language in best_models:\n",
        "    filename = f\"{MODELS_DIR}/{language}_{'lib' if USE_LIBROSA else 'psf'}{'_pitch_sync'}.pkl\"\n",
        "    with open(filename, \"wb\") as file:\n",
        "        pkl.dump(best_models[language], file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fa58dad",
      "metadata": {
        "id": "5fa58dad"
      },
      "outputs": [],
      "source": [
        "acc, cf_matrix, language_mappings = test(best_models, USE_DELTAS, USE_LIBROSA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e71eee3",
      "metadata": {
        "id": "8e71eee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9859154929577465\n",
            "{'assamese': 0, 'bengali': 1, 'gujarathi': 2, 'manipuri': 3, 'marathi': 4, 'odia': 5, 'telugu': 6}\n",
            "Confusion Matrix:\n",
            " [[20.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. 21.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0. 20.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. 20.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. 20.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. 20.  0.]\n",
            " [ 0.  0.  1.  0.  0.  0. 19.]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\",  acc)\n",
        "print(language_mappings)\n",
        "print(\"Confusion Matrix:\\n\", cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d9c2c33",
      "metadata": {
        "id": "4d9c2c33"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assamese</th>\n",
              "      <th>bengali</th>\n",
              "      <th>gujarathi</th>\n",
              "      <th>manipuri</th>\n",
              "      <th>marathi</th>\n",
              "      <th>odia</th>\n",
              "      <th>telugu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>assamese</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bengali</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gujarathi</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>manipuri</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marathi</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>odia</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>telugu</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           assamese  bengali  gujarathi  manipuri  marathi  odia  telugu\n",
              "assamese         20        0          1         0        0     0       0\n",
              "bengali           0       21          0         0        0     0       0\n",
              "gujarathi         0        0         20         0        0     0       1\n",
              "manipuri          0        0          0        20        0     0       0\n",
              "marathi           0        0          0         0       20     0       0\n",
              "odia              0        0          0         0        0    20       0\n",
              "telugu            0        0          0         0        0     0      19"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = {}\n",
        "for i, language in enumerate(language_mappings):\n",
        "    df[language] = cf_matrix[i].astype(np.int32)\n",
        "df = pd.DataFrame(df, columns=language_mappings, index=language_mappings)\n",
        "df.to_csv(f\"{MAIN_DIR}/{'lib' if USE_LIBROSA else 'psf'}{'_pitch_sync'}.csv\", columns=language_mappings, index=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e86908f0",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "0767bc91d6a71e2fcfaa3e34ef6383eab4c19e062312dc5ecfe1a27dfdba791e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
